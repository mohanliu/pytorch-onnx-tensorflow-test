{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduce example from Medium article [link](https://towardsdatascience.com/converting-a-simple-deep-learning-model-from-pytorch-to-tensorflow-b6b353351f5d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/random_normal.py:9: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/random_uniform.py:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/upsample.py:13: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check `onnx` and `onnx-tf` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "pip_packages = subprocess.run(['pip', 'freeze'], stdout=subprocess.PIPE)\n",
    "pip_packages_list = pip_packages.stdout.decode('utf-8').strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['onnx==1.5.0', 'onnx-tf==1.2.1']\n",
      "Correct onnx version!\n",
      "Correct onnx-tf version!\n",
      "onnx==1.5.0\n",
      "onnx-tf==1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(list(filter(lambda x: 'onnx' in x, pip_packages_list)))\n",
    "\n",
    "if 'onnx==1.5.0' not in pip_packages_list:\n",
    "    print(\"onnx version is incorrect!\")\n",
    "    print(\"Target version: 1.5.0\")\n",
    "    print(\"Re-Installing packages...\")\n",
    "    os.system('pip install onnx==1.5.0')\n",
    "else:\n",
    "    print(\"Correct onnx version!\")\n",
    "    \n",
    "if 'onnx-tf==1.2.1' not in pip_packages_list:\n",
    "    print(\"onnx-tf version is incorrect!\")\n",
    "    print(\"Target version: 1.2.1\")\n",
    "    print(\"Re-Installing packages...\")\n",
    "    os.system('pip install onnx-tf==1.2.1')\n",
    "else:\n",
    "    print(\"Correct onnx-tf version!\")\n",
    "    \n",
    "!pip freeze |grep onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 8000\n",
    "test_size = 2000\n",
    "\n",
    "input_size = 20\n",
    "hidden_sizes = [50, 50]\n",
    "output_size = 1\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device used:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8000, 20)\n",
      "Shape of X_train: (2000, 20)\n",
      "Shape of y_train: (8000,)\n",
      "Shape of y_test: (8000,)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/X_train.pk'):\n",
    "    X_train = np.random.randn(train_size, input_size).astype(np.float32)\n",
    "    with open('data/X_train.pk', 'wb') as p:\n",
    "        pickle.dump(X_train, p)\n",
    "else: \n",
    "    with open('data/X_train.pk', 'rb') as p:\n",
    "        X_train = pickle.load(p)\n",
    "        \n",
    "if not os.path.exists('data/X_test.pk'):\n",
    "    X_test = np.random.randn(test_size, input_size).astype(np.float32)\n",
    "    with open('data/X_test.pk', 'wb') as p:\n",
    "        pickle.dump(X_test, p)\n",
    "else: \n",
    "    with open('data/X_test.pk', 'rb') as p:\n",
    "        X_test = pickle.load(p)\n",
    "\n",
    "if not os.path.exists('data/y_train.pk'):\n",
    "    y_train = np.random.randint(num_classes, size=train_size)\n",
    "    with open('data/y_train.pk', 'wb') as p:\n",
    "        pickle.dump(y_train, p)\n",
    "else: \n",
    "    with open('data/y_train.pk', 'rb') as p:\n",
    "        y_train = pickle.load(p)\n",
    "    \n",
    "if not os.path.exists('data/y_test.pk'):\n",
    "    y_test = np.random.randint(num_classes, size=train_size)\n",
    "    with open('data/y_test.pk', 'wb') as p:\n",
    "        pickle.dump(y_test, p)\n",
    "else: \n",
    "    with open('data/y_test.pk', 'rb') as p:\n",
    "        y_test = pickle.load(p)\n",
    "\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_train:', X_test.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build or load a pytorch toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_RETRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (fc0): Linear(in_features=20, out_features=50, bias=True)\n",
       "  (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (last_fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.fcs = []  # List of fully connected layers\n",
    "        in_size = input_size\n",
    "        \n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = nn.Linear(in_features=in_size, out_features=next_size)\n",
    "            in_size = next_size\n",
    "            self.__setattr__('fc{}'.format(i), fc)  # set name for each fullly connected layer\n",
    "            self.fcs.append(fc)\n",
    "            \n",
    "        self.last_fc = nn.Linear(in_features=in_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            x = fc(x)\n",
    "            x = nn.ReLU()(x)\n",
    "        out = self.last_fc(x)\n",
    "        return nn.Sigmoid()(out)\n",
    "    \n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "if os.path.exists('models/model_simple.pt') == False or FORCE_RETRAIN == True:\n",
    "    print(\"Building model...\")\n",
    "    \n",
    "    # Create DataLoaders for training and test set, for batch training and evaluation\n",
    "    train_loader = DataLoader(dataset=SimpleDataset(X_train, y_train), batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=SimpleDataset(X_test, y_test), batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Initialize the model and set device to be used\n",
    "    model_pytorch = SimpleModel(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "    model_pytorch = model_pytorch.to(device)\n",
    "    \n",
    "    # Set binary cross entropy loss since 2 classes only\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model_pytorch.parameters(), lr=1e-3)\n",
    "       \n",
    "    # Train model\n",
    "    num_epochs = 20\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model_pytorch.train() # Turn on training mode\n",
    "\n",
    "        train_loss_total = 0 # A flag to record the total loss for each epoch\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.float().to(device) # Prepare data (features/target)\n",
    "            optimizer.zero_grad() # Initialize paramters\n",
    "            output = model_pytorch(data) # Forward propogation\n",
    "            train_loss = criterion(output, target) # Compute the loss\n",
    "            train_loss.backward() # Back-propogate the loss\n",
    "            optimizer.step() # Update the weights/biases\n",
    "            train_loss_total += train_loss.item() * data.size(0) # Add up the loss for each batch\n",
    "\n",
    "        print('Epoch {} completed. Train loss is {:.3f}'.format(epoch + 1, train_loss_total / train_size))\n",
    "    print('Time taken to completed {} epochs: {:.2f} minutes'.format(num_epochs, (time.time() - time_start) / 60))\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model_pytorch.state_dict(), './models/model_simple.pt')\n",
    "    print('Model has been saved to ./models/model_simple.pt.')\n",
    "else:\n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model_pytorch = SimpleModel(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "    model_pytorch.load_state_dict(torch.load('./models/model_simple.pt'))\n",
    "    \n",
    "# Display model\n",
    "display(model_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "`model.train()` and `model.eval()` will affect the process for only particular models. Check the [source code](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalulate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pytorch_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_pytorch_model:\n",
    "    model_pytorch.eval()\n",
    "\n",
    "    test_loss_total = 0\n",
    "    total_num_corrects = 0\n",
    "    threshold = 0.5\n",
    "    time_start = time.time()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_pytorch(data)\n",
    "        train_loss = criterion(output, target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_total += train_loss.item() * data.size(0)\n",
    "\n",
    "        pred = (output >= threshold).view_as(target)  # to make pred have same shape as target\n",
    "        num_correct = torch.sum(pred == target.byte()).item()\n",
    "        total_num_corrects += num_correct\n",
    "\n",
    "    print('Evaluation completed. Test loss is {:.3f}'.format(test_loss_total / test_size))\n",
    "    print('Test accuracy is {:.3f}'.format(total_num_corrects / test_size))\n",
    "    print('Time taken to complete evaluation: {:.2f} seconds'.format((time.time() - time_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_to_ONNX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./models/model_simple.onnx') == False or FORCE_to_ONNX == True:\n",
    "    # Single pass of dummy variable required\n",
    "    dummy_input = torch.from_numpy(X_test[0].reshape(1, -1)).float().to(device)\n",
    "    dummy_output = model_pytorch(dummy_input)\n",
    "    print(dummy_output)\n",
    "    \n",
    "    # Export to ONNX format\n",
    "    torch.onnx.export(\n",
    "        model_pytorch, dummy_input, \n",
    "        './models/model_simple.onnx', input_names=['input'], output_names=['output']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ONNX model and convert to TensorFlow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_to_TF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./models/model_simple.pb') == False or FORCE_to_TF == True:\n",
    "    model_onnx = onnx.load('./models/model_simple.onnx')\n",
    "\n",
    "    tf_rep = prepare(model_onnx)\n",
    "\n",
    "    # Print out tensors and placeholders in model (helpful during inference in TensorFlow)\n",
    "    print(tf_rep.tensor_dict)\n",
    "\n",
    "    # Export model as .pb file\n",
    "    tf_rep.export_graph('./models/model_simple.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing inference in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_graph = load_pb('./models/model_simple.pb')\n",
    "sess = tf.Session(graph=tf_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Const_2' type=Const>,\n",
       " <tf.Operation 'Const_3' type=Const>,\n",
       " <tf.Operation 'Const_4' type=Const>,\n",
       " <tf.Operation 'Const_5' type=Const>,\n",
       " <tf.Operation 'input' type=Placeholder>,\n",
       " <tf.Operation 'flatten/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'flatten/Reshape' type=Reshape>,\n",
       " <tf.Operation 'transpose/perm' type=Const>,\n",
       " <tf.Operation 'transpose' type=Transpose>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'mul_1/x' type=Const>,\n",
       " <tf.Operation 'mul_1' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Relu' type=Relu>,\n",
       " <tf.Operation 'flatten_1/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'flatten_1/Reshape' type=Reshape>,\n",
       " <tf.Operation 'transpose_1/perm' type=Const>,\n",
       " <tf.Operation 'transpose_1' type=Transpose>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'mul_2/x' type=Const>,\n",
       " <tf.Operation 'mul_2' type=Mul>,\n",
       " <tf.Operation 'mul_3/x' type=Const>,\n",
       " <tf.Operation 'mul_3' type=Mul>,\n",
       " <tf.Operation 'add_1' type=Add>,\n",
       " <tf.Operation 'Relu_1' type=Relu>,\n",
       " <tf.Operation 'flatten_2/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'flatten_2/Reshape' type=Reshape>,\n",
       " <tf.Operation 'transpose_2/perm' type=Const>,\n",
       " <tf.Operation 'transpose_2' type=Transpose>,\n",
       " <tf.Operation 'MatMul_2' type=MatMul>,\n",
       " <tf.Operation 'mul_4/x' type=Const>,\n",
       " <tf.Operation 'mul_4' type=Mul>,\n",
       " <tf.Operation 'mul_5/x' type=Const>,\n",
       " <tf.Operation 'mul_5' type=Mul>,\n",
       " <tf.Operation 'add_2' type=Add>,\n",
       " <tf.Operation 'Sigmoid' type=Sigmoid>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = tf_graph.get_tensor_by_name('Sigmoid:0')\n",
    "input_tensor = tf_graph.get_tensor_by_name('input:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input:0' shape=(1, 20) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total cases: 2000\n",
      "# of correct cases: 2000\n"
     ]
    }
   ],
   "source": [
    "total_test_cases = 0\n",
    "correct_cases = 0\n",
    "for test_id in range(2000):\n",
    "    total_test_cases += 1\n",
    "    tf_output = sess.run(output_tensor, feed_dict={input_tensor: X_test[test_id].reshape(1, -1)})\n",
    "    pt_output = model_pytorch(torch.from_numpy(X_test[test_id].reshape(1, -1)).float())\n",
    "    \n",
    "    tf_data = tf_output[0][0]\n",
    "    pt_data = pt_output.data.numpy()[0][0]\n",
    "    \n",
    "    if tf_data - pt_data < 1e-5:\n",
    "        correct_cases += 1\n",
    "        \n",
    "print(\"# of total cases: %d\" %total_test_cases)\n",
    "print(\"# of correct cases: %d\" %correct_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
